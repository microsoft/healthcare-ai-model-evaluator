{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef7f32a0",
   "metadata": {},
   "source": [
    "# Hugging Face dataset export walkthrough (text)\n",
    "Use this notebook as a step-by-step template for pulling public datasets from Hugging Face, persisting each split locally, and ending up with clean `.jsonl` files organized under `data/`. It installs `datasets`, shows how to specify a target directory, iterates over every split (train/test/etc.), and streams each example to disk so you can immediately plug the results into downstream tooling.\n",
    "\n",
    "The dataset(s) in this example are used for demonstration purposes only. Microsoft does not endorse them specifically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec41f8e4",
   "metadata": {},
   "source": [
    "# Download ncbi/MedCalc-Bench-v1.1\n",
    "This section installs the necessary Hugging Face tooling, fetches the `ncbi/MedCalc-Bench-v1.1` dataset from Hugging Face, and persists each available split as a JSON Lines file under `data/medcalc-bench-v1.1`.\n",
    "\n",
    "`\n",
    "@misc{khandekar2024medcalcbench,\n",
    "      title={MedCalc-Bench: Evaluating Large Language Models for Medical Calculations}, \n",
    "      author={Nikhil Khandekar and Qiao Jin and Guangzhi Xiong and Soren Dunn and Serina S Applebaum and Zain Anwar and Maame Sarfo-Gyamfi and Conrad W Safranek and Abid A Anwar and Andrew Zhang and Aidan Gilson and Maxwell B Singer and Amisha Dave and Andrew Taylor and Aidong Zhang and Qingyu Chen and Zhiyong Lu},\n",
    "      year={2024},\n",
    "      eprint={2406.12036},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}\n",
    "}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"install\", \"datasets\", \"huggingface-hub\"],\n",
    "    check=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee7521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "target_dir = Path(\"data/medcalc-bench-v1.1\")\n",
    "target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset = load_dataset(\"ncbi/MedCalc-Bench-v1.1\")\n",
    "\n",
    "for split_name, split_dataset in dataset.items():\n",
    "    output_path = target_dir / f\"{split_name}.jsonl\"\n",
    "    with output_path.open(\"w\", encoding=\"utf-8\") as output_file:\n",
    "        for record in split_dataset:\n",
    "            json.dump(record, output_file, ensure_ascii=False)\n",
    "            output_file.write(\"\\n\")\n",
    "    print(f\"Saved {split_name} split to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9465fda",
   "metadata": {},
   "source": [
    "Run the second code cell to download the data; the JSONL files are saved per split in `data/medcalc-bench-v1.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df7292",
   "metadata": {},
   "source": [
    "# Download ncbi/TrialGPT-Criterion-Annotations\n",
    "This section loads the `ncbi/TrialGPT-Criterion-Annotations` dataset from Hugging Face and writes each split as JSON Lines into `data/trialgpt-criterion-annotations`.\n",
    "\n",
    "\n",
    "Citation:\n",
    "Qiao Jin, Zifeng Wang, Charalampos S. Floudas, Fangyuan Chen, Changlin Gong, Dara Bracken-Clarke, Elisabetta Xue, Yifan Yang, Jimeng Sun, Zhiyong Lu. Matching Patients to Clinical Trials with Large Language Models. Nat Commun. 2024;15:9074. doi: 10.1038/s41467-024-53081-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5651a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "target_dir = Path(\"data/trialgpt-criterion-annotations\")\n",
    "target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset = load_dataset(\"ncbi/TrialGPT-Criterion-Annotations\")\n",
    "\n",
    "for split_name, split_dataset in dataset.items():\n",
    "    output_path = target_dir / f\"{split_name}.jsonl\"\n",
    "    with output_path.open(\"w\", encoding=\"utf-8\") as output_file:\n",
    "        for record in split_dataset:\n",
    "            json.dump(record, output_file, ensure_ascii=False)\n",
    "            output_file.write(\"\\n\")\n",
    "    print(f\"Saved {split_name} split to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7752f5",
   "metadata": {},
   "source": [
    "# Download rungalileo/medical_transcription_4\n",
    "This section loads the `rungalileo/medical_transcription_4` dataset from Hugging Face and exports each split as JSON Lines files under `data/medical_transcription_4`.\n",
    "\n",
    "(could not locate citation info. please let us know if you think you should be cited / credited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a28946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "target_dir = Path(\"data/medical_transcription_4\")\n",
    "target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset = load_dataset(\"rungalileo/medical_transcription_4\")\n",
    "\n",
    "for split_name, split_dataset in dataset.items():\n",
    "    output_path = target_dir / f\"{split_name}.jsonl\"\n",
    "    with output_path.open(\"w\", encoding=\"utf-8\") as output_file:\n",
    "        for record in split_dataset:\n",
    "            json.dump(record, output_file, ensure_ascii=False)\n",
    "            output_file.write(\"\\n\")\n",
    "    print(f\"Saved {split_name} split to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
